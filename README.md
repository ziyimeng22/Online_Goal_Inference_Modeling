

````markdown
# Online Goal Inference Modeling

<div align="center">
  <img src="https://img.shields.io/badge/python-3.8+-blue.svg"  alt="PythonÂ Version"/>
  <img src="https://img.shields.io/badge/framework-flask-green.svg" alt="Framework"/>
  <img src="https://img.shields.io/badge/socketio-4.7.5-orange.svg" alt="SocketIOÂ Version"/>
  <img src="https://img.shields.io/badge/license-MIT-lightgrey.svg" alt="License"/>
</div>

<p align="center">
  <img src="https://raw.githubusercontent.com/ziyimeng22/Online_Goal_Inference_Modeling/main/public/assets/demo.gif"
       alt="DemoÂ Animation" width="600"/>
</p>

## ğŸ” Overview
This repository implements a **realâ€‘time Bayesian framework** for inferring human goals from observed actions in interactive environments.  
Beliefs about user intentions are updated onâ€‘theâ€‘fly as they navigate, demonstrating how AI can reason about human behavior in real time.

The approach combines **MarkovÂ DecisionÂ Processes (MDPs)**, **ValueÂ Iteration**, and **Bayesian inference** to model human decisionâ€‘makingâ€”even when that behavior is boundedly rational.

---

## âœ¨ Key Features
- **Online Bayesian Inference** â€“ live posterior updates as actions stream in  
- **Bounded Rationality** â€“ softmax temperature captures subâ€‘optimal decisions  
- **Interactive Visualization** â€“ web UI shows evolving belief states  
- **Flexible Maps** â€“ dropâ€‘in support for custom goals and obstacle layouts  
- **Realâ€‘time Comms** â€“ FlaskÂ +Â SocketIO for bidirectional serverâ€‘client updates  

---

## ğŸ§  The Science Behind It

### Bayesian Goal Inference
\[
P(\text{goal}\mid\text{actions}) \;\propto\; P(\text{actions}\mid\text{goal}) \times P(\text{goal})
\]

| Term | Meaning |
| ---- | -------- |
| **\(P(\text{goal}\mid\text{actions})\)** | Posterior over goals |
| **\(P(\text{actions}\mid\text{goal})\)** | Likelihood of observed actions given a goal |
| **\(P(\text{goal})\)** | Prior over goals |

### Value IterationÂ &Â Policies
```python
# Optimal stateâ€‘value function for each candidate goal
V[s] = max_a sum_{s'} T(s, a, s') * (R(s, a, s') + Î³ * V[s'])
````

Action likelihood under softmax policy:

```python
P(a | s, goal) âˆ exp(Q(s, a, goal) / temperature)
```

---

## ğŸš€ Getting Started

### Prerequisites

* PythonÂ 3.8+
* Node.jsÂ 12+ (frontâ€‘end build)

### Installation

```bash
# 1Â â€“Â Clone the repo
git clone https://github.com/ziyimeng22/Online_Goal_Inference_Modeling.git
cd Online_Goal_Inference_Modeling

# 2Â â€“Â Python deps
pip install -r requirements.txt

# 3Â â€“Â Frontâ€‘end deps
npm install
```

### Running

```bash
# Start FlaskÂ +Â SocketIO server
python server.py
# then open http://localhost:3000 in your browser
```

---

## ğŸ“Š Example Usage

```python
from inference import UpdatePosteriorClass

custom_map = {
    "playerPosition": (0, 0),
    "goals":  [(9, 0), (9, 4), (9, 9)],
    "blocks": [(4, 0), (4, 1), (7, 1), (4, 3)]
}

update_posterior = UpdatePosteriorClass(custom_map)

state  = (5, 5)   # position after action
action = (1, 0)   # move right
posterior = update_posterior(state, action)

print(posterior)
# {'G1': 0.28, 'G2': 0.42, 'G3': 0.30}
```

---

## ğŸ“‚ Project Structure

```
Online_Goal_Inference_Modeling/
â”œâ”€â”€ ValueIteration.py    # Valueâ€‘iteration algorithm
â”œâ”€â”€ inference.py         # Core Bayesian inference
â”œâ”€â”€ server.py            # FlaskÂ +Â SocketIO backend
â”œâ”€â”€ package.json         # Node.js deps
â”œâ”€â”€ requirements.txt     # Python deps
â”œâ”€â”€ public/              # Frontâ€‘end assets
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ style.css
â”‚   â”œâ”€â”€ client.js
â”‚   â””â”€â”€ assets/
â””â”€â”€ .vscode/             # EditorÂ config
```

---

## ğŸ”¬ Technical Approach

1. **Policyâ€¯Computation** â€“ compute optimal policy for each goal (ValueÂ Iteration).
2. **Actionâ€¯Likelihood** â€“ score observed actions under each policy.
3. **Posteriorâ€¯Update** â€“ apply Bayesâ€™ rule with softmax rationality.
4. **Temporalâ€¯Decay** â€“ optional decay on priors to capture changing intent.

<p align="center">
  <img src="https://raw.githubusercontent.com/ziyimeng22/Online_Goal_Inference_Modeling/main/public/assets/algorithm_flow.png"
       alt="AlgorithmÂ Workflow" width="700"/>
</p>

---

## ğŸ® Interactive Demo

| Color              | Meaning              |
| ------------------ | -------------------- |
| ğŸŸ© green           | goal cells           |
| ğŸŸ¥ red             | obstacles            |
| ğŸŸ¦ blue            | player               |
| ğŸŸ¨ yellowÂ â†’Â orange | posterior over goals |

Move aroundâ€”beliefs update live!

---

## ğŸ“š References

* Baker,Â C.â€¯L.,â€¯Saxe,Â R.,Â &â€¯Tenenbaum,Â J.â€¯B. (2009). *Action understanding as inverse planning*. **Cognition,Â 113**(3),Â 329â€‘349.
* Zhiâ€‘Xuan,Â T.,â€¯Mann,Â J.â€¯J.,Â Silver,Â T.,Â Tenenbaum,Â J.â€¯B.,Â &â€¯Mansinghka,Â V.â€¯K. (2020). *Online Bayesian Goal Inference for Boundedlyâ€‘Rational Planning Agents*. **NeurIPSÂ 33**.

---

## ğŸ“„ License

Distributed under the **MIT License**.
See [`LICENSE`](LICENSE) for details.

---

## ğŸ“§ Contact

**YourÂ Name** Â· [your.email@example.com](mailto:your.email@example.com)
ProjectÂ URL â†’ [https://github.com/ziyimeng22/Online\_Goal\_Inference\_Modeling](https://github.com/ziyimeng22/Online_Goal_Inference_Modeling)

<p align="center">
  <a href="https://github.com/ziyimeng22/Online_Goal_Inference_Modeling/stargazers">
    <img src="https://img.shields.io/github/stars/ziyimeng22/Online_Goal_Inference_Modeling?style=social"
         alt="Stars"/>
  </a>
  <a href="https://github.com/ziyimeng22/Online_Goal_Inference_Modeling/network/members">
    <img src="https://img.shields.io/github/forks/ziyimeng22/Online_Goal_Inference_Modeling?style=social"
         alt="Forks"/>
  </a>
  <a href="https://github.com/ziyimeng22/Online_Goal_Inference_Modeling/issues">
    <img src="https://img.shields.io/github/issues/ziyimeng22/Online_Goal_Inference_Modeling?style=social"
         alt="Issues"/>
  </a>
</p>
```
